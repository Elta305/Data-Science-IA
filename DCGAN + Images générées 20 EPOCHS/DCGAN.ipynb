{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset disponible sur https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\n",
    "Output cleared sinon fichier trop gros pour github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import (Reshape,LeakyReLU,Dropout,Conv2DTranspose, Add, Conv2D, MaxPool2D, Dense,\n",
    "                                     Flatten, InputLayer, BatchNormalization, Input)\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IM_SHAPE = (64, 64, 3)\n",
    "LEARNING_RATE = 2e-4\n",
    "LATENT_DIM = 100\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"img_align_celeba/img_align_celeba/\", label_mode=None, image_size=(IM_SHAPE[0], IM_SHAPE[1]), batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    return tf.cast(image, tf.float32) / 127.5 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    dataset\n",
    "    .map(preprocess)\n",
    "    .unbatch()\n",
    "    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n",
    "    .batch(BATCH_SIZE, drop_remainder = True)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_dataset.take(1):\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "k = 0\n",
    "n = 4\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, 2, k+1)\n",
    "    plt.imshow((d[i] + 1) / 2)\n",
    "    plt.axis(\"off\")\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    Input(shape = (LATENT_DIM)),\n",
    "    Dense(4 * 4 * LATENT_DIM),\n",
    "    Reshape((4, 4, LATENT_DIM)),\n",
    "    \n",
    "    Conv2DTranspose(512, kernel_size = 4, strides = 2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "\n",
    "    Conv2DTranspose(256, kernel_size = 4, strides = 2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "\n",
    "    Conv2DTranspose(128, kernel_size = 4, strides = 2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "\n",
    "    Conv2DTranspose(3, kernel_size = 4, strides = 2, activation=tf.keras.activations.tanh, padding='same'),\n",
    "], name = 'generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = tf.keras.Sequential([\n",
    "    Input(shape = (IM_SHAPE[0], IM_SHAPE[1], 3)),\n",
    "    \n",
    "    Conv2D(64, kernel_size = 4, strides = 2, padding='same'),\n",
    "    LeakyReLU(0.2),\n",
    "\n",
    "    Conv2D(128, kernel_size = 4, strides = 2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "\n",
    "    Conv2D(256, kernel_size = 4, strides = 2, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "\n",
    "    Conv2D(1, kernel_size = 4, strides = 2, padding='same'),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name = 'discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowImage(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        n = 6\n",
    "        k = 0\n",
    "        out = self.model.generator(tf.random.normal(shape=(36, self.latent_dim)))\n",
    "        plt.figure(figsize=(16, 16))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                ax = plt.subplot(n, n, k+1)\n",
    "                plt.imshow((out[k]+1) / 2)\n",
    "                plt.axis('off')\n",
    "                k += 1\n",
    "        plt.savefig(f\"generated/gen_images_epochs={epoch+1}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = tf.keras.metrics.Mean(name='d_loss')\n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name='g_loss')                \n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        # Discriminator\n",
    "        random_noise = tf.random.normal(shape=(batch_size, LATENT_DIM))\n",
    "        fake_images = self.generator(random_noise)\n",
    "        real_labels = tf.ones((batch_size, 1)) + 0.25 * tf.random.uniform((batch_size, 1), minval=-1, maxval=1)\n",
    "        fake_labels = tf.zeros((batch_size, 1)) + 0.25 * tf.random.uniform((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as recorder:\n",
    "            real_predictions = self.discriminator(real_images)\n",
    "            d_loss_real = self.loss_fn(real_labels, real_predictions)\n",
    "            fake_predictions = self.discriminator(fake_images)\n",
    "            g_loss_fake = self.loss_fn(fake_labels, fake_predictions)\n",
    "\n",
    "            d_loss = d_loss_real + g_loss_fake\n",
    "\n",
    "        partial_derivatives = recorder.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(partial_derivatives, self.discriminator.trainable_weights))\n",
    "        \n",
    "        # Generator\n",
    "        random_noise = tf.random.normal(shape=(batch_size, LATENT_DIM))\n",
    "        flipped_fake_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as recorder:\n",
    "            fake_predictions = self.discriminator(self.generator(random_noise))\n",
    "            g_loss = self.loss_fn(flipped_fake_labels, fake_predictions)\n",
    "\n",
    "        partial_derivatives = recorder.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(partial_derivatives, self.generator.trainable_weights))\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {'d_loss': self.d_loss_metric.result(), 'g_loss': self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminator, generator)\n",
    "gan.compile(\n",
    "    d_optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE, beta_1 = 0.5),\n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE, beta_1 = 0.5),\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_devices = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=my_devices, device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gan.fit(train_dataset, epochs = EPOCHS, callbacks = [ShowImage(LATENT_DIM)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['d_loss'])\n",
    "plt.plot(history.history['g_loss'])\n",
    "plt.title('GAN Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['d_loss', 'g_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
